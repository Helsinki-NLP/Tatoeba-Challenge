# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.swe-fin 	| 44.6 	| 0.668 	| 2500 	| 13711 	| 0.951 |








# opus-2021-02-17.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.3 	| 0.618 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.7 	| 0.670 	| 2500 	| 13711 	| 0.954 |








# opus-2021-02-18.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 25.8 	| 0.614 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.4 	| 0.669 	| 2500 	| 13711 	| 0.954 |








# opus-2021-02-22.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.zip)
* test set translations: [opus-2021-02-22.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.test.txt)
* test set scores: [opus-2021-02-22.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.3 	| 0.615 	| 523 	| 7638 	| 0.997 |
| MeMAD-YLE-test.FIH-SWE.swe-fin 	| 12.2 	| 0.427 	| 625 	| 6075 	| 0.868 |
| MeMAD-YLE-test.FIN-SWE.swe-fin 	| 20.8 	| 0.492 	| 1252 	| 10812 	| 0.976 |
| MeMAD-YLE-test.FIN-SWH.swe-fin 	| 15.9 	| 0.444 	| 2837 	| 23153 	| 0.942 |
| Tatoeba-test.swe-fin 	| 44.5 	| 0.668 	| 2500 	| 13711 	| 0.956 |








# opusTCv20210807+bt-2021-08-26.zip

* dataset: opusTCv20210807+bt
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-08-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.zip)
* test set translations: [opusTCv20210807+bt-2021-08-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.test.txt)
* test set scores: [opusTCv20210807+bt-2021-08-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 30.2 	| 0.648 	| 523 	| 7638 	| 0.983 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 45.8 	| 0.681 	| 2841 	| 15621 	| 0.958 |







# opusTCv20210807+bt-2021-11-09.zip

* dataset: opusTCv20210807+bt
* model: transformer-big-align
* source language(s): swe
* target language(s): fin
* raw source language(s): swe
* raw target language(s): fin
* model: transformer-big-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-11-09.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-11-09.zip)
* test set translations: [opusTCv20210807+bt-2021-11-09.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-11-09.test.txt)
* test set scores: [opusTCv20210807+bt-2021-11-09.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-11-09.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 29.8 	| 0.648 	| 523 	| 7638 	| 0.980 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 45.1 	| 0.678 	| 2841 	| 15621 	| 0.956 |






# opusTCv20210807+bt-2021-12-08.zip

* dataset: opusTCv20210807+bt
* model: transformer-big
* source language(s): swe
* target language(s): fin
* raw source language(s): swe
* raw target language(s): fin
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-12-08.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-12-08.zip)
* test set translations: [opusTCv20210807+bt-2021-12-08.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-12-08.test.txt)
* test set scores: [opusTCv20210807+bt-2021-12-08.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-12-08.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 30.8 	| 0.6536 	| 523 	| 7638 	| 0.982 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 46.3 	| 0.6885 	| 2841 	| 15621 	| 0.960 |






# opusTCv20210807+pbt+bt-2022-01-15.zip

* dataset: opusTCv20210807+pbt+bt
* model: transformer-big
* source language(s): swe
* target language(s): fin
* raw source language(s): swe
* raw target language(s): fin
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+pbt+bt-2022-01-15.zip](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+pbt+bt-2022-01-15.zip)
* test set translations: [opusTCv20210807+pbt+bt-2022-01-15.test.txt](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+pbt+bt-2022-01-15.test.txt)
* test set scores: [opusTCv20210807+pbt+bt-2022-01-15.eval.txt](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+pbt+bt-2022-01-15.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 31.3 	| 65.385 	| 523 	| 7638 	| 0.983 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 45.5 	| 67.892 	| 2841 	| 15621 	| 0.957 |





# opusTCv20210807+nopar+ft95-2022-01-18.zip

* dataset: opusTCv20210807+nopar+ft95
* model: transformer-tiny11-align
* source language(s): swe
* target language(s): fin
* raw source language(s): swe
* raw target language(s): fin
* model: transformer-tiny11-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+nopar+ft95-2022-01-18.zip](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+nopar+ft95-2022-01-18.zip)
* test set translations: [opusTCv20210807+nopar+ft95-2022-01-18.test.txt](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+nopar+ft95-2022-01-18.test.txt)
* test set scores: [opusTCv20210807+nopar+ft95-2022-01-18.eval.txt](https://object.pouta.csc.fi/OPUS-MT-dev/swe-fin/opusTCv20210807+nopar+ft95-2022-01-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.9 	| 62.387 	| 523 	| 7638 	| 0.985 |
| Tatoeba-test-v2021-08-07.intgemm8.alphas.swe-fin 	| 43.1 	| 66.558 	| 2841 	| 15621 	| 0.963 |
| Tatoeba-test-v2021-08-07.intgemm8.swe-fin 	| 43.6 	| 66.880 	| 2841 	| 15621 	| 0.962 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 43.8 	| 67.332 	| 2841 	| 15621 	| 0.966 |


# opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.zip

* dataset: opusTCv20210807+news+pbt+bt
* model: transformer-big
* source language(s): swe
* target language(s): fin
* raw source language(s): swe
* raw target language(s): fin
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.zip)
* test set translations: [opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.test.txt)
* test set scores: [opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+news+pbt+bt_transformer-big_2023-04-13.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 31.2 	| 0.65577 	| 523 	| 7638 	| 0.981 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 46.1 	| 0.68962 	| 2841 	| 15621 	| 0.965 |

