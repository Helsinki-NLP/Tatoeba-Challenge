# opus-2020-07-04.zip

* dataset: opus
* model: transformer
* source language(s): bel bel_Latn bul bul_Latn ces csb_Latn dsb hsb mkd orv_Cyrl pol rue rus slv ukr
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-04.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-eng/opus-2020-07-04.zip)
* test set translations: [opus-2020-07-04.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-eng/opus-2020-07-04.test.txt)
* test set scores: [opus-2020-07-04.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/sla-eng/opus-2020-07-04.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.bel-eng.bel.eng 	| 39.7 	| 0.586 |
| Tatoeba-test.bul-eng.bul.eng 	| 54.7 	| 0.692 |
| Tatoeba-test.ces-eng.ces.eng 	| 52.6 	| 0.684 |
| Tatoeba-test.csb-eng.csb.eng 	| 17.1 	| 0.382 |
| Tatoeba-test.dsb-eng.dsb.eng 	| 17.3 	| 0.359 |
| Tatoeba-test.hsb-eng.hsb.eng 	| 31.2 	| 0.502 |
| Tatoeba-test.mkd-eng.mkd.eng 	| 52.8 	| 0.665 |
| Tatoeba-test.multi.eng 	| 52.0 	| 0.671 |
| Tatoeba-test.orv-eng.orv.eng 	| 13.0 	| 0.287 |
| Tatoeba-test.pol-eng.pol.eng 	| 49.9 	| 0.663 |
| Tatoeba-test.rue-eng.rue.eng 	| 19.7 	| 0.363 |
| Tatoeba-test.rus-eng.rus.eng 	| 52.8 	| 0.677 |
| Tatoeba-test.slv-eng.slv.eng 	| 41.5 	| 0.595 |
| Tatoeba-test.ukr-eng.ukr.eng 	| 52.1 	| 0.674 |

