# opus-2020-07-04.zip

* dataset: opus
* model: transformer
* source language(s): eng est fin fkv_Latn hun kpv liv_Latn mhr sme udm vro
* target language(s): eng izh kkt krl mdf myv sma
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* download: [opus-2020-07-04.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-04.zip)
* test set translations: [opus-2020-07-04.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-04.test.txt)
* test set scores: [opus-2020-07-04.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-04.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 20.9 	| 0.494 |
| newsdev2018-enet-esteng.est.eng 	| 24.5 	| 0.525 |
| newssyscomb2009-huneng.hun.eng 	| 18.7 	| 0.475 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.472 |
| newstest2015-enfi-fineng.fin.eng 	| 22.2 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.8 	| 0.524 |
| newstest2017-enfi-fineng.fin.eng 	| 26.7 	| 0.542 |
| newstest2018-enet-esteng.est.eng 	| 24.7 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.7 	| 0.476 |
| newstest2019-fien-fineng.fin.eng 	| 23.3 	| 0.513 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.9 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.9 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 0.9 	| 0.137 |
| Tatoeba-test.est-eng.est.eng 	| 37.5 	| 0.559 |
| Tatoeba-test.fin-eng.fin.eng 	| 31.0 	| 0.507 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 7.1 	| 0.334 |
| Tatoeba-test.hun-eng.hun.eng 	| 29.3 	| 0.481 |
| Tatoeba-test.izh-eng.izh.eng 	| 11.0 	| 0.315 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.6 	| 0.120 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.9 	| 0.094 |
| Tatoeba-test.krl-eng.krl.eng 	| 13.0 	| 0.328 |
| Tatoeba-test.liv-eng.liv.eng 	| 0.4 	| 0.092 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.1 	| 0.141 |
| Tatoeba-test.multi.eng 	| 46.2 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.7 	| 0.128 |
| Tatoeba-test.sma-eng.sma.eng 	| 0.3 	| 0.089 |
| Tatoeba-test.sme-eng.sme.eng 	| 1.8 	| 0.142 |
| Tatoeba-test.udm-eng.udm.eng 	| 1.2 	| 0.118 |

# opus-2020-07-14.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-14.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-14.zip)
* test set translations: [opus-2020-07-14.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-14.test.txt)
* test set scores: [opus-2020-07-14.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-14.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 20.9 	| 0.494 |
| newsdev2018-enet-esteng.est.eng 	| 24.5 	| 0.525 |
| newssyscomb2009-huneng.hun.eng 	| 18.7 	| 0.475 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.472 |
| newstest2015-enfi-fineng.fin.eng 	| 22.2 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.8 	| 0.524 |
| newstest2017-enfi-fineng.fin.eng 	| 26.7 	| 0.542 |
| newstest2018-enet-esteng.est.eng 	| 24.7 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.7 	| 0.476 |
| newstest2019-fien-fineng.fin.eng 	| 23.3 	| 0.513 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.9 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.9 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 0.9 	| 0.137 |
| Tatoeba-test.est-eng.est.eng 	| 37.5 	| 0.559 |
| Tatoeba-test.fin-eng.fin.eng 	| 31.0 	| 0.507 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 7.1 	| 0.334 |
| Tatoeba-test.hun-eng.hun.eng 	| 29.3 	| 0.481 |
| Tatoeba-test.izh-eng.izh.eng 	| 11.0 	| 0.315 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.6 	| 0.120 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.9 	| 0.094 |
| Tatoeba-test.krl-eng.krl.eng 	| 13.0 	| 0.328 |
| Tatoeba-test.liv-eng.liv.eng 	| 0.4 	| 0.092 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.1 	| 0.141 |
| Tatoeba-test.multi.eng 	| 46.2 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.7 	| 0.128 |
| Tatoeba-test.sma-eng.sma.eng 	| 0.3 	| 0.089 |
| Tatoeba-test.sme-eng.sme.eng 	| 1.8 	| 0.142 |
| Tatoeba-test.udm-eng.udm.eng 	| 1.2 	| 0.118 |

# opus-2020-07-20.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-20.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-20.zip)
* test set translations: [opus-2020-07-20.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-20.test.txt)
* test set scores: [opus-2020-07-20.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-20.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 20.9 	| 0.494 |
| newsdev2018-enet-esteng.est.eng 	| 24.5 	| 0.525 |
| newssyscomb2009-huneng.hun.eng 	| 18.7 	| 0.475 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.472 |
| newstest2015-enfi-fineng.fin.eng 	| 22.2 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.8 	| 0.524 |
| newstest2017-enfi-fineng.fin.eng 	| 26.7 	| 0.542 |
| newstest2018-enet-esteng.est.eng 	| 24.7 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.7 	| 0.476 |
| newstest2019-fien-fineng.fin.eng 	| 23.3 	| 0.513 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.9 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.9 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 0.9 	| 0.137 |
| Tatoeba-test.est-eng.est.eng 	| 37.5 	| 0.559 |
| Tatoeba-test.fin-eng.fin.eng 	| 31.0 	| 0.507 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 7.1 	| 0.334 |
| Tatoeba-test.hun-eng.hun.eng 	| 29.3 	| 0.481 |
| Tatoeba-test.izh-eng.izh.eng 	| 11.0 	| 0.315 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.6 	| 0.120 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.9 	| 0.094 |
| Tatoeba-test.krl-eng.krl.eng 	| 13.0 	| 0.328 |
| Tatoeba-test.liv-eng.liv.eng 	| 0.4 	| 0.092 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.1 	| 0.141 |
| Tatoeba-test.multi.eng 	| 46.2 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.7 	| 0.128 |
| Tatoeba-test.sma-eng.sma.eng 	| 0.3 	| 0.089 |
| Tatoeba-test.sme-eng.sme.eng 	| 1.8 	| 0.142 |
| Tatoeba-test.udm-eng.udm.eng 	| 1.2 	| 0.118 |

# opus-2020-07-27.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-27.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-27.zip)
* test set translations: [opus-2020-07-27.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-27.test.txt)
* test set scores: [opus-2020-07-27.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus-2020-07-27.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 20.9 	| 0.494 |
| newsdev2018-enet-esteng.est.eng 	| 24.5 	| 0.525 |
| newssyscomb2009-huneng.hun.eng 	| 18.7 	| 0.475 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.472 |
| newstest2015-enfi-fineng.fin.eng 	| 22.2 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.8 	| 0.524 |
| newstest2017-enfi-fineng.fin.eng 	| 26.7 	| 0.542 |
| newstest2018-enet-esteng.est.eng 	| 24.7 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.7 	| 0.476 |
| newstest2019-fien-fineng.fin.eng 	| 23.3 	| 0.513 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.9 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.9 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 0.9 	| 0.137 |
| Tatoeba-test.est-eng.est.eng 	| 37.5 	| 0.559 |
| Tatoeba-test.fin-eng.fin.eng 	| 31.0 	| 0.507 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 7.1 	| 0.334 |
| Tatoeba-test.hun-eng.hun.eng 	| 29.3 	| 0.481 |
| Tatoeba-test.izh-eng.izh.eng 	| 11.0 	| 0.315 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.6 	| 0.120 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.9 	| 0.094 |
| Tatoeba-test.krl-eng.krl.eng 	| 13.0 	| 0.328 |
| Tatoeba-test.liv-eng.liv.eng 	| 0.4 	| 0.092 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.1 	| 0.141 |
| Tatoeba-test.multi.eng 	| 46.2 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.7 	| 0.128 |
| Tatoeba-test.sma-eng.sma.eng 	| 0.3 	| 0.089 |
| Tatoeba-test.sme-eng.sme.eng 	| 1.8 	| 0.142 |
| Tatoeba-test.udm-eng.udm.eng 	| 1.2 	| 0.118 |

# opus2m-2020-08-01.zip

* dataset: opus2m
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus2m-2020-08-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.zip)
* test set translations: [opus2m-2020-08-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.test.txt)
* test set scores: [opus2m-2020-08-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/urj-eng/opus2m-2020-08-01.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 22.7 	| 0.511 |
| newsdev2018-enet-esteng.est.eng 	| 26.6 	| 0.545 |
| newssyscomb2009-huneng.hun.eng 	| 21.3 	| 0.493 |
| newstest2009-huneng.hun.eng 	| 20.1 	| 0.487 |
| newstest2015-enfi-fineng.fin.eng 	| 23.9 	| 0.521 |
| newstest2016-enfi-fineng.fin.eng 	| 25.8 	| 0.542 |
| newstest2017-enfi-fineng.fin.eng 	| 28.9 	| 0.562 |
| newstest2018-enet-esteng.est.eng 	| 27.0 	| 0.552 |
| newstest2018-enfi-fineng.fin.eng 	| 21.2 	| 0.492 |
| newstest2019-fien-fineng.fin.eng 	| 25.3 	| 0.531 |
| newstestB2016-enfi-fineng.fin.eng 	| 21.3 	| 0.500 |
| newstestB2017-enfi-fineng.fin.eng 	| 24.4 	| 0.528 |
| newstestB2017-fien-fineng.fin.eng 	| 24.4 	| 0.528 |
| Tatoeba-test.chm-eng.chm.eng 	| 0.8 	| 0.131 |
| Tatoeba-test.est-eng.est.eng 	| 34.5 	| 0.526 |
| Tatoeba-test.fin-eng.fin.eng 	| 28.1 	| 0.485 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 6.8 	| 0.335 |
| Tatoeba-test.hun-eng.hun.eng 	| 25.1 	| 0.452 |
| Tatoeba-test.izh-eng.izh.eng 	| 11.6 	| 0.224 |
| Tatoeba-test.kom-eng.kom.eng 	| 2.4 	| 0.110 |
| Tatoeba-test.krl-eng.krl.eng 	| 18.6 	| 0.365 |
| Tatoeba-test.liv-eng.liv.eng 	| 0.5 	| 0.078 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.5 	| 0.117 |
| Tatoeba-test.multi.eng 	| 47.8 	| 0.646 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.5 	| 0.101 |
| Tatoeba-test.sma-eng.sma.eng 	| 1.2 	| 0.110 |
| Tatoeba-test.sme-eng.sme.eng 	| 1.5 	| 0.147 |
| Tatoeba-test.udm-eng.udm.eng 	| 1.0 	| 0.130 |

