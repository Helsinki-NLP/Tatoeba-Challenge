# opus-2020-06-28.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kkt kpv krl liv_Latn mdf mhr myv udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-28.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.zip)
* test set translations: [opus-2020-06-28.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.test.txt)
* test set scores: [opus-2020-06-28.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.3 	| 0.496 |
| newsdev2018-enet-esteng.est.eng 	| 24.6 	| 0.526 |
| newssyscomb2009-huneng.hun.eng 	| 19.6 	| 0.480 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.473 |
| newstest2015-enfi-fineng.fin.eng 	| 21.9 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 24.0 	| 0.526 |
| newstest2017-enfi-fineng.fin.eng 	| 26.3 	| 0.541 |
| newstest2018-enet-esteng.est.eng 	| 24.9 	| 0.533 |
| newstest2018-enfi-fineng.fin.eng 	| 20.1 	| 0.479 |
| newstest2019-fien-fineng.fin.eng 	| 23.2 	| 0.510 |
| newstestB2016-enfi-fineng.fin.eng 	| 20.0 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.8 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.8 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.4 	| 0.168 |
| Tatoeba-test.est-eng.est.eng 	| 53.1 	| 0.689 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.6 	| 0.642 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.1 	| 0.368 |
| Tatoeba-test.hun-eng.hun.eng 	| 45.0 	| 0.622 |
| Tatoeba-test.izh-eng.izh.eng 	| 65.1 	| 0.795 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 1.1 	| 0.143 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.8 	| 0.102 |
| Tatoeba-test.krl-eng.krl.eng 	| 29.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 2.2 	| 0.091 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.131 |
| Tatoeba-test.multi.eng 	| 45.8 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.6 	| 0.118 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.7 	| 0.176 |

# opus-2020-07-04.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kkt kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-04.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-04.zip)
* test set translations: [opus-2020-07-04.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-04.test.txt)
* test set scores: [opus-2020-07-04.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-04.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.1 	| 0.493 |
| newsdev2018-enet-esteng.est.eng 	| 24.3 	| 0.522 |
| newssyscomb2009-huneng.hun.eng 	| 19.0 	| 0.476 |
| newstest2009-huneng.hun.eng 	| 18.1 	| 0.470 |
| newstest2015-enfi-fineng.fin.eng 	| 22.4 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.7 	| 0.523 |
| newstest2017-enfi-fineng.fin.eng 	| 26.2 	| 0.538 |
| newstest2018-enet-esteng.est.eng 	| 24.8 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.5 	| 0.475 |
| newstest2019-fien-fineng.fin.eng 	| 23.1 	| 0.509 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.7 	| 0.508 |
| newstestB2017-fien-fineng.fin.eng 	| 22.7 	| 0.508 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.1 	| 0.159 |
| Tatoeba-test.est-eng.est.eng 	| 52.9 	| 0.682 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.3 	| 0.639 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.0 	| 0.376 |
| Tatoeba-test.hun-eng.hun.eng 	| 44.6 	| 0.619 |
| Tatoeba-test.izh-eng.izh.eng 	| 38.4 	| 0.608 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.5 	| 0.142 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.6 	| 0.081 |
| Tatoeba-test.krl-eng.krl.eng 	| 32.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 1.4 	| 0.080 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.119 |
| Tatoeba-test.multi.eng 	| 45.4 	| 0.626 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.4 	| 0.109 |
| Tatoeba-test.sma-eng.sma.eng 	| 2.3 	| 0.116 |
| Tatoeba-test.sme-eng.sme.eng 	| 8.3 	| 0.204 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.8 	| 0.148 |

# opus-2020-07-14.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-14.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-14.zip)
* test set translations: [opus-2020-07-14.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-14.test.txt)
* test set scores: [opus-2020-07-14.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-14.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.1 	| 0.493 |
| newsdev2018-enet-esteng.est.eng 	| 24.3 	| 0.522 |
| newssyscomb2009-huneng.hun.eng 	| 19.0 	| 0.476 |
| newstest2009-huneng.hun.eng 	| 18.1 	| 0.470 |
| newstest2015-enfi-fineng.fin.eng 	| 22.4 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.7 	| 0.523 |
| newstest2017-enfi-fineng.fin.eng 	| 26.2 	| 0.538 |
| newstest2018-enet-esteng.est.eng 	| 24.8 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.5 	| 0.475 |
| newstest2019-fien-fineng.fin.eng 	| 23.1 	| 0.509 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.7 	| 0.508 |
| newstestB2017-fien-fineng.fin.eng 	| 22.7 	| 0.508 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.1 	| 0.159 |
| Tatoeba-test.est-eng.est.eng 	| 52.9 	| 0.682 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.3 	| 0.639 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.0 	| 0.376 |
| Tatoeba-test.hun-eng.hun.eng 	| 44.6 	| 0.619 |
| Tatoeba-test.izh-eng.izh.eng 	| 38.4 	| 0.608 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.5 	| 0.142 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.6 	| 0.081 |
| Tatoeba-test.krl-eng.krl.eng 	| 32.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 1.4 	| 0.080 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.119 |
| Tatoeba-test.multi.eng 	| 45.4 	| 0.626 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.4 	| 0.109 |
| Tatoeba-test.sma-eng.sma.eng 	| 2.3 	| 0.116 |
| Tatoeba-test.sme-eng.sme.eng 	| 8.3 	| 0.204 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.8 	| 0.148 |

# opus-2020-07-19.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-19.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-19.zip)
* test set translations: [opus-2020-07-19.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-19.test.txt)
* test set scores: [opus-2020-07-19.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-19.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.1 	| 0.493 |
| newsdev2018-enet-esteng.est.eng 	| 24.3 	| 0.522 |
| newssyscomb2009-huneng.hun.eng 	| 19.0 	| 0.476 |
| newstest2009-huneng.hun.eng 	| 18.1 	| 0.470 |
| newstest2015-enfi-fineng.fin.eng 	| 22.4 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.7 	| 0.523 |
| newstest2017-enfi-fineng.fin.eng 	| 26.2 	| 0.538 |
| newstest2018-enet-esteng.est.eng 	| 24.8 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.5 	| 0.475 |
| newstest2019-fien-fineng.fin.eng 	| 23.1 	| 0.509 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.7 	| 0.508 |
| newstestB2017-fien-fineng.fin.eng 	| 22.7 	| 0.508 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.1 	| 0.159 |
| Tatoeba-test.est-eng.est.eng 	| 52.9 	| 0.682 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.3 	| 0.639 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.0 	| 0.376 |
| Tatoeba-test.hun-eng.hun.eng 	| 44.6 	| 0.619 |
| Tatoeba-test.izh-eng.izh.eng 	| 38.4 	| 0.608 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.5 	| 0.142 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.6 	| 0.081 |
| Tatoeba-test.krl-eng.krl.eng 	| 32.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 1.4 	| 0.080 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.119 |
| Tatoeba-test.multi.eng 	| 45.4 	| 0.626 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.4 	| 0.109 |
| Tatoeba-test.sma-eng.sma.eng 	| 2.3 	| 0.116 |
| Tatoeba-test.sme-eng.sme.eng 	| 8.3 	| 0.204 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.8 	| 0.148 |

