# opusTCv20210807_transformer-big_2022-07-28.zip

* dataset: opusTCv20210807
* model: transformer-big
* source language(s): dan isl nno nob swe
* target language(s): heb
* raw source language(s): dan isl nno nob swe
* raw target language(s): heb
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807_transformer-big_2022-07-28.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmq-heb/opusTCv20210807_transformer-big_2022-07-28.zip)
* test set translations: [opusTCv20210807_transformer-big_2022-07-28.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmq-heb/opusTCv20210807_transformer-big_2022-07-28.test.txt)
* test set scores: [opusTCv20210807_transformer-big_2022-07-28.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmq-heb/opusTCv20210807_transformer-big_2022-07-28.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test-v2021-08-07.dan-heb 	| 53.8 	| 0.78325 	| 29 	| 185 	| 1.000 |
| Tatoeba-test-v2021-08-07.isl-heb 	| 38.2 	| 0.60671 	| 11 	| 45 	| 1.000 |
| Tatoeba-test-v2021-08-07.multi-heb 	| 46.9 	| 0.69942 	| 66 	| 360 	| 1.000 |
| Tatoeba-test-v2021-08-07.nor-heb 	| 50.6 	| 0.62528 	| 23 	| 115 	| 1.000 |
| Tatoeba-test-v2021-08-07.swe-heb 	| 76.2 	| 0.89334 	| 3 	| 15 	| 1.000 |

