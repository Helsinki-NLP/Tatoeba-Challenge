# opus-2021-02-15.zip

* dataset: opus
* model: transformer-align
* source language(s): eng
* target language(s): fra
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-15.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fra/opus-2021-02-15.zip)
* test set translations: [opus-2021-02-15.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fra/opus-2021-02-15.test.txt)
* test set scores: [opus-2021-02-15.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fra/opus-2021-02-15.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdiscussdev2015-enfr-engfra.eng.fra 	| 33.6 	| 0.603 |
| newsdiscusstest2015-enfr-engfra.eng.fra 	| 40.1 	| 0.643 |
| newssyscomb2009-engfra.eng.fra 	| 29.4 	| 0.583 |
| news-test2008-engfra.eng.fra 	| 27.4 	| 0.553 |
| newstest2009-engfra.eng.fra 	| 29.4 	| 0.577 |
| newstest2010-engfra.eng.fra 	| 32.8 	| 0.597 |
| newstest2011-engfra.eng.fra 	| 34.2 	| 0.611 |
| newstest2012-engfra.eng.fra 	| 31.8 	| 0.592 |
| newstest2013-engfra.eng.fra 	| 33.2 	| 0.589 |
| Tatoeba-test.eng.fra 	| 50.5 	| 0.669 |
| Tatoeba-test.eng-fra.eng.fra 	| 50.5 	| 0.669 |
| tico19-test-engfra.eng.fra 	| 41.6 	| 0.638 |

